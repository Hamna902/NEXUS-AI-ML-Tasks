### ğŸ¤– NEXUS-AI ML INTERNSHIP
## ğŸ†” ID: NEXUS-079
# ğŸ›ï¸ Retail Analytics Data Science Portfolio

This repository contains a collection of **Jupyter notebooks** demonstrating various data science tasks applied to retail datasets.  
The tasks cover exploratory data analysis (EDA), interactive dashboards, machine learning models for customer churn prediction, product recommendation systems, and time series forecasting for sales.  

These notebooks are designed to provide **actionable insights** for a fictional retail company like GlobalMart, focusing on customer behavior, sales trends, and predictive modeling.

ğŸ“‚ The notebooks are self-contained, with code, explanations, visualizations, and interpretations.  
ğŸ“Š They use real-world datasets such as Online Retail, TMDB Movies, Telco Customer Churn, and Superstore Sales.

---

## ğŸ“‘ Table of Contents
- [ğŸ“– Overview](#overview)
- [ğŸ“ Tasks and Notebooks](#tasks-and-notebooks)
- [ğŸ“‚ Datasets](#datasets)
- [âš™ï¸ Requirements](#requirements)
- [ğŸ’» Installation](#installation)
- [â–¶ï¸ Usage](#usage)
- [ğŸ“œ License](#license)

---

## ğŸ“– Overview
This project showcases end-to-end **data science workflows**:
- ğŸ§¹ **Data Cleaning and EDA**: Understanding datasets through statistics and visualizations.
- ğŸ“Š **Interactive Dashboards**: Building user-friendly visualizations with filtering capabilities.
- ğŸ¤– **Machine Learning**: Classification models for churn prediction, recommendation systems, and time series forecasting.
- ğŸ’¡ **Business Insights**: Interpretations and recommendations tied to business goals, such as customer retention, product recommendations, and sales forecasting.

The notebooks are numbered as tasks (1-6) and can be run independently.

---

## ğŸ“ Tasks and Notebooks
1. **Task 1: Exploratory Data Analysis (EDA) on Online Retail Dataset**  
   ğŸ“‚ File: `task1.ipynb`  
   ğŸ” Description: Loads, cleans, and analyzes the Online Retail dataset. Includes descriptive statistics, visualizations (histograms, bar charts, line plots), and insights on customer spending, top products, seasonal trends, and geographic sales.

2. **Task 2: Interactive Dashboard for Retail Sales Insights**  
   ğŸ“‚ File: `task2.ipynb`  
   ğŸ“Š Description: Builds an interactive Dash dashboard with Plotly visualizations. Features include a country filter, histogram of customer sales, bar chart of top products, and a line chart of sales trends. Includes a ğŸ¥ demo video.

3. **Task 3: Predicting Customer Churn for GlobalMart**  
   ğŸ“‚ File: `task3.ipynb`  
   ğŸ¤– Description: Uses Logistic Regression to predict customer churn on the Telco dataset. Includes preprocessing, model training, evaluation (accuracy, confusion matrix), and visualizations. Focuses on identifying at-risk customers.

4. **Task 4: Optimizing Churn Prediction (Advanced Classification)**  
   ğŸ“‚ File: `task4.ipynb`  
   âš¡ Description: Improves the churn model with Random Forest, SMOTE for class imbalance, and scaling. Compares models with metrics (accuracy, precision, recall, F1-score). Recommends the best model for business goals.

5. **Task 5: Building a Product Recommendation System**  
   ğŸ“‚ File: `task5.ipynb`  
   ğŸ¬ Description: Implements a content-based recommendation system for movies using TF-IDF and cosine similarity on the TMDB dataset. Recommends similar movies based on user input.

6. **Task 6: Forecasting Future Sales (Time Series Analysis)**  
   ğŸ“‚ File: `task6.ipynb`  
   â³ Description: Uses SARIMA for sales forecasting on the Superstore dataset. Includes aggregation, stationarity checks, model training, evaluation (MAE, RMSE), and a 30-day forecast with confidence intervals.

---

## ğŸ“‚ Datasets
- ğŸ›’ **Online Retail Dataset**: Used in Tasks 1-2 (`OnlineRetail.csv` / `Cleaned_OnlineRetail.csv`)
- ğŸ“ **Telco Customer Churn**: Used in Tasks 3-4 (`WA_Fn-UseC_-Telco-Customer-Churn.csv`)
- ğŸ¬ **TMDB 5000 Movies**: Used in Task 5 (`tmdb_5000_movies.csv`)
- ğŸª **Superstore Sales**: Used in Task 6 (`train.csv`)

Datasets are assumed to be in the same directory as the notebooks. They can be downloaded from Kaggle or UCI repositories.

---

## âš™ï¸ Requirements
- ğŸ Python 3.9+
- ğŸ“¦ Libraries:
  - pandas
  - numpy
  - scikit-learn
  - matplotlib
  - seaborn
  - plotly
  - dash
  - statsmodels
  - imbalanced-learn
  - jupyter

ğŸ“Œ See `requirements.txt` for the full list.

---

## ğŸ’» Installation
1. Clone the repository:
```git clone https://github.com/Hamna902/NEXUS-AI-ML-Tasks.git
cd NEXUS-AI-ML-Tasks
```
2. Install dependencies:
```
pip install -r requirements.txt
```
3. Download datasets and place them in the root directory.
## â–¶ï¸ Usage
1. Open Jupyter Notebook:
2. Navigate to and run each taskX.ipynb.
3. For Task  (Dashboard): Run the notebook to start the Dash server â†’ open http://127.0.0.1:8050/. Use the dropdown for country filter.
4. Ensure datasets are loaded correctly (paths may need adjustment).

## ğŸ“œ License

This project is by HAMNA NAZAR âœ¨